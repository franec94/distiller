# Scheduler for training Siren DNN, quantized using the DoReFa scheme
# Activations: 8-bits, Weights: 4-bits
# See:
#  https://intellabs.github.io/distiller/algo_quantization.html#dorefa
#  https://arxiv.org/abs/1606.06160
#
# Command line for training (running from the compress_classifier.py directory):
# python compress_classifier.py --arch alexnet_bn <path_to_imagenet_dataset> -p=50 --epochs=110 --compress=../quantization/quant_aware_train/alexnet_bn_dorefa.yaml -j 22 --lr 0.0002 --wd 0.0001 --vs 0

quantizers:
  dorefa_quantizer:
    class: DorefaQuantizer
    bits_activations: 32
    bits_weights: 8
    overrides:
    # Don't quantize first and last layer
      net.0.linear:
        bits_activations: null
        bits_weights: null
        bits_bias: null
      net.1.linear:
        bits_weights: 8
        bits_bias: null
        bits_activations: null
      net.2.linear:
        bits_weights: 8
        bits_activations: null
        bits_bias: null
      net.3.linear:
        bits_weights: 8
        bits_activations: null
        bits_bias: null
      net.4.linear:
        bits_weights: 8
        bits_activations: null
        bits_bias: null
      net.5.linear:
        bits_weights: 8
        bits_activations: null
        bits_bias: null
      net.6:
        bits_weights: null
        bits_bias: null
        bits_activations: null

policies:
    - quantizer:
        instance_name: dorefa_quantizer
      starting_epoch: 0
      ending_epoch: 440729
      frequency: 5
