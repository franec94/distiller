{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "distiller-siren-train-test-case-study-3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nOurhnGJ34XX",
        "E_XNWOFb3-uK",
        "-Rka87pahCXA",
        "YSMDhVWvhFDx",
        "6g6yHBYY2GHD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XeY789JtbVD"
      },
      "source": [
        "# Siren Case Study: Training-Test via Distiller Framework\n",
        "---\n",
        "### Training a siren model, enabling also pruning, quantization if necessary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty3yV03Q3vy0"
      },
      "source": [
        "## Options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYiSuEnGsaPU"
      },
      "source": [
        "#@title Github related infos:\n",
        "#@markdown ---\n",
        "PROJECT_NAME_PATH = '/content/distiller' #@param {type:\"string\"}\n",
        "\n",
        "    \n",
        "GITHUB_PROJECT_URL = 'https://github.com/franec94/distiller.git' #@param {type:\"string\"}\n",
        "BRANCH_NAME = 'siren-support' #@param {type:\"string\"}\n",
        "CMD_TOOL_NAME = '' #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJLHzM0-tLUE"
      },
      "source": [
        "#@title Install Dependencies -> Options:\n",
        "#@markdown ---\n",
        "CLONE_GITHUB_PROJECT = True #@param {type:\"boolean\"}\n",
        "INSTALL_SOME_LIBS = False #@param {type:\"boolean\"}\n",
        "INSTALL_DISTILLER_PIP_REQ = False #@param {type:\"boolean\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNyhWxxOZgJw"
      },
      "source": [
        "#@title Running -> Options:\n",
        "#@markdown ---\n",
        "RUN_COLAB_CODE = False #@param {type:\"boolean\"}\n",
        "RUN_MAIN_SIREN_BASE = False #@param {type:\"boolean\"}\n",
        "RUN_MAIN_SIREN_APP = True #@param {type:\"boolean\"}\n",
        "EVAL_MODEL = False #@param {type:\"boolean\"}\n",
        "PLAIN_TRAINING = False #@param {type:\"boolean\"}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2varknOBtz4J"
      },
      "source": [
        "#@title Dir Path(s) for Logging -> options:\n",
        "#@markdown ---\n",
        "LOGGING_ROOT = \"/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/\" #@param [\"/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/sensitivity_pruning/\", \"/content/pruning/sensitivity_pruning\", \"/content/pruning/level_pruning\", \"/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/\"] {allow-input: true}\n",
        "LOGGING_ROOT_EVAL = \"/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/eval-res\" #@param {type:\"string\"}\n",
        "EXPERIMENT_NAME = 'train' #@param {type:\"string\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4H1JPIstpq"
      },
      "source": [
        "#@title DNN Arch. -> Options:\n",
        "#@markdown ---\n",
        "N_HF = 64 #@param {type:\"integer\"}\n",
        "N_HL = 5 #@param {type:\"integer\"}\n",
        "NUM_EPOCHS =  35000#@param {type:\"integer\"}\n",
        "SIDELENGHT = 256 #@param {type:\"integer\"}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKhDWvoBsr_a"
      },
      "source": [
        "#@title Pruning -> Options:\n",
        "#@markdown ---\n",
        "PRUNE_MODEL_AGP  = True #@param {type:\"boolean\"}\n",
        "SENSITIVITY_PRUNING  = False #@param {type:\"boolean\"}\n",
        "LEVEL_PRUNING  = False #@param {type:\"boolean\"}\n",
        "PRUNING_SCHEDULER_FILE = \"/content/siren64_5.schedule_agp.yaml\" #@param {type:\"string\"}\n",
        "STATE_DICT_MODEL_FILE = \"/content/_mid_ckpt_epoch_299999.pth.tar\" #@param {type:\"string\"}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syIbC8hVjhKw"
      },
      "source": [
        "#@title Tensorboard -> options:\n",
        "#@markdown ---\n",
        "# RUN_TENSORBOARD_UTIL = False #@param {type:\"boolean\"}\n",
        "LOG_DIR = \"/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/sensitivity_pruning/\" #@param {type:\"string\"}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMq0gvaI3sKT"
      },
      "source": [
        "## Setup Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCHyLaOf31nt"
      },
      "source": [
        "### Clone Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Xg5uZOuBh6"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P0EpvmRr5A2",
        "outputId": "9a9df38e-f21a-41c9-fd6c-8ee0a99c5e7c"
      },
      "source": [
        "# Setup wd to remove trash\n",
        "\n",
        "if CLONE_GITHUB_PROJECT:\n",
        "    # Remove trash\n",
        "    import os\n",
        "    if os.path.exists(f'{PROJECT_NAME_PATH}') and os.path.isdir(f'{PROJECT_NAME_PATH}'):\n",
        "        print(\"Cleaning from old project...\")\n",
        "        !rm -r {PROJECT_NAME_PATH}\n",
        "    else:\n",
        "        print(\"No project found.\")\n",
        "        pass\n",
        "\n",
        "    import os\n",
        "    logs_base_dir = os.path.join(\"/content/outputs\", \"summaries\")\n",
        "    os.makedirs(logs_base_dir, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(PROJECT_NAME_PATH) is False:\n",
        "        !git clone {GITHUB_PROJECT_URL}\n",
        "        os.chdir(PROJECT_NAME_PATH)\n",
        "        !git checkout {BRANCH_NAME}\n",
        "        if CMD_TOOL_NAME == None or len(CMD_TOOL_NAME) == 0:\n",
        "            full_path_cmd = os.path.join(PROJECT_NAME_PATH, f'{PROJECT_NAME_PATH}/')\n",
        "            os.chdir(full_path_cmd)\n",
        "        else:\n",
        "            full_path_cmd = os.path.join(PROJECT_NAME_PATH, f'{PROJECT_NAME_PATH}/{CMD_TOOL_NAME}')\n",
        "            os.chdir(full_path_cmd)\n",
        "    else:\n",
        "        os.chdir(PROJECT_NAME_PATH)\n",
        "        !git checkout {BRANCH_NAME}\n",
        "        !git fetch\n",
        "        if CMD_TOOL_NAME == None or len(CMD_TOOL_NAME) == 0:\n",
        "            full_path_cmd = os.path.join(PROJECT_NAME_PATH, f'{PROJECT_NAME_PATH}/')\n",
        "            os.chdir(full_path_cmd)\n",
        "        else:\n",
        "            full_path_cmd = os.path.join(PROJECT_NAME_PATH, f'{PROJECT_NAME_PATH}/{CMD_TOOL_NAME}')\n",
        "            os.chdir(full_path_cmd)\n",
        "        pass\n",
        "    pass\n",
        "else:\n",
        "    print(\"No github project cloned and no branch activated and switched to!\")\n",
        "    pass"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning from old project...\n",
            "Cloning into 'distiller'...\n",
            "remote: Enumerating objects: 462, done.\u001b[K\n",
            "remote: Counting objects: 100% (462/462), done.\u001b[K\n",
            "remote: Compressing objects: 100% (284/284), done.\u001b[K\n",
            "remote: Total 7670 (delta 304), reused 326 (delta 172), pack-reused 7208\u001b[K\n",
            "Receiving objects: 100% (7670/7670), 54.94 MiB | 29.83 MiB/s, done.\n",
            "Resolving deltas: 100% (5414/5414), done.\n",
            "Branch 'siren-support' set up to track remote branch 'siren-support' from 'origin'.\n",
            "Switched to a new branch 'siren-support'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GoBmT2WuRUp",
        "outputId": "ad7ab495-f15e-45d1-ebae-6873094e1c07"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/distiller\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNVhhr_jy8gZ"
      },
      "source": [
        "# !pip install -e .\n",
        "if INSTALL_DISTILLER_PIP_REQ:\n",
        "    !pip install -r requirements.txt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOurhnGJ34XX"
      },
      "source": [
        "### Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn8rIEwlvBH0"
      },
      "source": [
        "# Installing third party dependencies\n",
        "if INSTALL_SOME_LIBS:\n",
        "    print(\"Installing required libraries...\")\n",
        "\n",
        "    old_requirements = '/content/tmp_requirements.txt'\n",
        "    !pip freeze > {old_requirements}\n",
        "    dependencies_list = \"pretrainedmodels,torchnet,xlsxwriter,gitpython,python-git,cmapy,sk-video,pytorch-model-summary,ConfigArgParse,tabulate,chart_studio,dash,dash_bootstrap_components\".split(\",\")\n",
        "\n",
        "    with open(old_requirements) as f:\n",
        "        old_requirements_list = f.read().split(\"\\n\")\n",
        "        for a_req in dependencies_list:\n",
        "            found_req = False\n",
        "            for old_req in old_requirements_list:\n",
        "                if old_req.startswith(a_req):\n",
        "                    print(f\"{a_req} already installed!\")\n",
        "                    found_req = True\n",
        "                    break\n",
        "            if found_req is False:\n",
        "                !pip install {a_req} -q\n",
        "        pass\n",
        "    !rm -f {old_requirements}\n",
        "    pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnXrYy2C4pSJ"
      },
      "source": [
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "\n",
        "if RUN_COLAB_CODE:\n",
        "\n",
        "\n",
        "    # --------------------------------------------- #\n",
        "    # Standard Library, plus some Third Party Libraries\n",
        "    # --------------------------------------------- #\n",
        "\n",
        "    DASH_TEMPLATES_LIST = [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]\n",
        "\n",
        "    from PIL import Image\n",
        "    from functools import partial\n",
        "    from pprint import pprint\n",
        "    from tqdm import tqdm\n",
        "    from typing import Tuple, Union\n",
        "\n",
        "\n",
        "    import configargparse\n",
        "    import copy\n",
        "    import collections\n",
        "    import datetime\n",
        "    import functools\n",
        "    import itertools\n",
        "    import h5py\n",
        "    import logging\n",
        "    import math\n",
        "    import os\n",
        "    import operator\n",
        "    import pickle\n",
        "    import random\n",
        "    import shutil\n",
        "    import sys\n",
        "    import re\n",
        "    import tabulate \n",
        "    import time\n",
        "    # import visdom\n",
        "\n",
        "\n",
        "    from collections import OrderedDict\n",
        "    import matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # --------------------------------------------- #\n",
        "    # Data Science and Machine Learning Libraries\n",
        "    # --------------------------------------------- #\n",
        "    import matplotlib\n",
        "    import matplotlib.pyplot as plt\n",
        "    matplotlib.style.use('ggplot')\n",
        "    import seaborn as sns\n",
        "\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import sklearn\n",
        "\n",
        "    from sklearn.model_selection import ParameterGrid\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    # --------------------------------------------- #\n",
        "    # Torch\n",
        "    # --------------------------------------------- #\n",
        "    import torch\n",
        "    try:\n",
        "        import torch\n",
        "        import torch.nn as nn\n",
        "        import torch.nn.functional as F\n",
        "        import torch.optim as optim\n",
        "        from torch.utils.data import DataLoader, Dataset\n",
        "        # import torch.quantization\n",
        "        # import torch.nn.utils.prune as prune\n",
        "\n",
        "        from torch import nn, optim\n",
        "\n",
        "    except Exception as err:\n",
        "        print(err)\n",
        "        print(\"torch not available!\")\n",
        "        pass\n",
        "\n",
        "    from numpy import linalg as LA\n",
        "    from scipy.stats import rankdata\n",
        "    from collections import OrderedDict\n",
        "    from torchvision import datasets, transforms\n",
        "    from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "    # --------------------------------------------- #\n",
        "    # Import: torch_pruning\n",
        "    # --------------------------------------------- #\n",
        "    # import torch_pruning as tp\n",
        "\n",
        "\n",
        "    # --------------------------------------------- #\n",
        "    # Import: TorchVision\n",
        "    # --------------------------------------------- #\n",
        "    try:\n",
        "        import torchvision\n",
        "        from torchvision import datasets\n",
        "        from torchvision import transforms\n",
        "        from torchvision.transforms import Resize, Compose, ToTensor, CenterCrop, Normalize\n",
        "        from torchvision.utils import save_image\n",
        "    except:\n",
        "        print(\"torchvision library not available!\")\n",
        "        pass\n",
        "\n",
        "    # Plotly imports.\n",
        "    # ----------------------------------------------- #\n",
        "    import chart_studio.plotly as py\n",
        "    import plotly.figure_factory as ff\n",
        "    import plotly.express as px\n",
        "\n",
        "    # --------------------------------------------- #\n",
        "    # Import: skimage\n",
        "    # --------------------------------------------- #\n",
        "    try:\n",
        "        import skimage\n",
        "        import skimage.metrics as skmetrics\n",
        "        from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "        from skimage.metrics import structural_similarity as ssim\n",
        "        from skimage.metrics import mean_squared_error\n",
        "    except:\n",
        "        print(\"skimage library not available!\")\n",
        "        pass"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_XNWOFb3-uK"
      },
      "source": [
        "### PyTorch Architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHQwNqhL4Djc"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    class SineLayer(nn.Module):\n",
        "        # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
        "        \n",
        "        # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
        "        # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
        "        # hyperparameter.\n",
        "        \n",
        "        # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
        "        # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
        "        \n",
        "        def __init__(self, in_features, out_features, bias=True,\n",
        "                    is_first=False, omega_0=30):\n",
        "            super().__init__()\n",
        "            self.omega_0 = omega_0\n",
        "            self.is_first = is_first\n",
        "            \n",
        "            self.in_features = in_features\n",
        "            self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "            \n",
        "            self.init_weights()\n",
        "            pass\n",
        "        \n",
        "        def init_weights(self):\n",
        "            with torch.no_grad():\n",
        "                if self.is_first:\n",
        "                    self.linear.weight.uniform_(-1 / self.in_features, \n",
        "                                                1 / self.in_features)      \n",
        "                else:\n",
        "                    self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
        "                                                np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "            pass\n",
        "            \n",
        "        def forward(self, input):\n",
        "            return torch.sin(self.omega_0 * self.linear(input))\n",
        "        \n",
        "        def forward_with_intermediate(self, input): \n",
        "            # For visualization of activation distributions\n",
        "            intermediate = self.omega_0 * self.linear(input)\n",
        "            return torch.sin(intermediate), intermediate\n",
        "        pass\n",
        "        \n",
        "        \n",
        "    class Siren(nn.Module):\n",
        "        def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
        "                    first_omega_0=30, hidden_omega_0=30.):\n",
        "            super().__init__()\n",
        "            \n",
        "            self.net = []\n",
        "            self.net.append(SineLayer(in_features, hidden_features, \n",
        "                                    is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "            for i in range(hidden_layers):\n",
        "                self.net.append(SineLayer(hidden_features, hidden_features, \n",
        "                                        is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "            if outermost_linear:\n",
        "                final_linear = nn.Linear(hidden_features, out_features)\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
        "                                                np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "                    \n",
        "                self.net.append(final_linear)\n",
        "            else:\n",
        "                self.net.append(SineLayer(hidden_features, out_features, \n",
        "                                        is_first=False, omega_0=hidden_omega_0))\n",
        "            \n",
        "            self.net = nn.Sequential(*self.net)\n",
        "            pass\n",
        "        \n",
        "        def forward(self, coords):\n",
        "            coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
        "            output = self.net(coords)\n",
        "            return output, coords        \n",
        "\n",
        "        def forward_with_activations(self, coords, retain_grad=False):\n",
        "            '''Returns not only model output, but also intermediate activations.\n",
        "            Only used for visualizing activations later!'''\n",
        "            activations = OrderedDict()\n",
        "\n",
        "            activation_count = 0\n",
        "            x = coords.clone().detach().requires_grad_(True)\n",
        "            activations['input'] = x\n",
        "            for i, layer in enumerate(self.net):\n",
        "                if isinstance(layer, SineLayer):\n",
        "                    x, intermed = layer.forward_with_intermediate(x)\n",
        "                    \n",
        "                    if retain_grad:\n",
        "                        x.retain_grad()\n",
        "                        intermed.retain_grad()\n",
        "                        \n",
        "                    activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
        "                    activation_count += 1\n",
        "                else: \n",
        "                    x = layer(x)\n",
        "                    \n",
        "                    if retain_grad:\n",
        "                        x.retain_grad()\n",
        "                        \n",
        "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
        "                activation_count += 1\n",
        "\n",
        "            return activations\n",
        "        pass"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKA9cO1r37po"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0D4tOEuz0M3"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/distiller')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc-IKCFGSHfp"
      },
      "source": [
        "import distiller"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MjxpEPzGykl6",
        "outputId": "c1b2c9f7-181d-43a4-c27f-f8ab2ecf1438"
      },
      "source": [
        "distiller.__version__"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Unknown'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rka87pahCXA"
      },
      "source": [
        "### Colab mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE7zHz_fr2Kx"
      },
      "source": [
        "import os\n",
        "import distiller\n",
        "import torch.nn as nn\n",
        "from distiller.models import register_user_model\n",
        "import distiller.apputils.siren_image_regressor as regressor"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUlcZfeX4VgJ"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    def siren_model_64_5():\n",
        "        img_siren = Siren(in_features=2, out_features=1, hidden_features=64, \n",
        "                  hidden_layers=5, outermost_linear=True)\n",
        "        return img_siren"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrpGKnfo3SMH"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    distiller.models.register_user_model(arch=\"SirenModel_64_5\", dataset=\"cameramen\", model=siren_model_64_5)\n",
        "    model = distiller.models.create_model(pretrained=False, dataset=\"cameramen\", arch=\"SirenModel_64_5\")\n",
        "    assert model is not None"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2QCI3osLupC"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    for name, module in model.named_modules():\n",
        "        print(name)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZEY8G1O5Pm9"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    def init_jupyter_default_args(args):\n",
        "        args.output_dir = '/content/' # None # \n",
        "        args.evaluate = False\n",
        "        args.seed = 0\n",
        "        args.deterministic = True\n",
        "        args.cpu = False\n",
        "        args.gpus = \"0\"\n",
        "        args.load_serialized = False\n",
        "        args.deprecated_resume = None\n",
        "        args.resumed_checkpoint_path = None\n",
        "        args.load_model_path = None\n",
        "        args.reset_optimizer = False\n",
        "        args.lr = args.momentum = args.weight_decay = 0.\n",
        "        args.compress = '/content/distiller/examples/agp-pruning/siren64-5_schedule_agp.yaml'\n",
        "        args.epochs = 0\n",
        "        args.activation_stats = list()\n",
        "        args.batch_size = 1\n",
        "        args.workers = 1\n",
        "        args.validation_split = 0.1\n",
        "        args.effective_train_size = args.effective_valid_size = args.effective_test_size = 1.\n",
        "        args.log_params_histograms = False\n",
        "        args.print_freq = 10\n",
        "        args.masks_sparsity = False\n",
        "        args.display_confusion = False\n",
        "        args.num_best_scores = 1\n",
        "        args.name = \"\"\n",
        "        args.kd_policy = None\n",
        "        # args.summary = \"sparsity\"\n",
        "        args.qe_stats_file = None\n",
        "        args.verbose = False\n",
        "        return args\n",
        "\n",
        "\n",
        "    def config_learner_args(args, arch, dataset, dataset_path, pretrained, adam_args, batch, epochs):\n",
        "        args.arch = f\"{arch}\"\n",
        "        args.dataset = f\"{dataset}\"\n",
        "        args.data = \"\"\n",
        "        args.pretrained = False\n",
        "        args.lr = adam_args[0]\n",
        "        args.momentum = adam_args[1]\n",
        "        args.weight_decay = adam_args[2]\n",
        "        args.batch_size = 1\n",
        "        args.epochs = epochs\n",
        "        return args"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OlAJI5AflcY"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    args = regressor.init_regressor_compression_arg_parser()\n",
        "    args, unknownargs = args.parse_known_args()\n",
        "    pprint(args)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5oYcZdH6Gdq"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    args = init_jupyter_default_args(args)\n",
        "    args.batch_size"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUN--sR1fuy8"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    args = config_learner_args(args, \"SirenModel_64_5\", \"cameramen\", \"\", False, (0.1, 0.0, 1e-4) , 1, 100)\n",
        "    args.arch, args.epochs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkgrmlFnaGeA"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    args.arch, args.verbose, args.print_freq"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7RZuDgC6kcw"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    app = regressor.SirenRegressorCompressor(args, script_dir=os.path.dirname(\".\"))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tMAe4gRM3lm"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %reload_ext tensorboard"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb2FswBZPpzx"
      },
      "source": [
        "# !kill 6966"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVT-QdsFM6-P"
      },
      "source": [
        "# %tensorboard --logdir /content/logs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGiV2QryRppS"
      },
      "source": [
        "# Run the training loop\n",
        "if RUN_COLAB_CODE:\n",
        "    perf_scores_history = app.run_training_loop()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5geXn_5jLYZm"
      },
      "source": [
        "if RUN_COLAB_CODE:\n",
        "    print(perf_scores_history[-1])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSMDhVWvhFDx"
      },
      "source": [
        "### Base mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pjrHhdPS6O_"
      },
      "source": [
        "if RUN_MAIN_SIREN_BASE:\n",
        "    !python main.py \\\n",
        "        --logging_root '/content/results/cameramen' \\\n",
        "        --experiment_name 'train' \\\n",
        "        --sidelength 256 \\\n",
        "        --num_epochs 100 \\\n",
        "        --n_hf 64  \\\n",
        "        --n_hl 5 \\\n",
        "        --lambda_L_1 0 \\\n",
        "        --lambda_L_2 0.0001 \\\n",
        "        --epochs_til_ckpt 10 \\\n",
        "        --seed 0 \\\n",
        "        --cuda \\\n",
        "        --train \\\n",
        "        --evaluate \\\n",
        "        --dynamic_quant qint8 qfloat16 \\\n",
        "        --verbose 0\n",
        "    pass"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXW6Y5zwhGp5"
      },
      "source": [
        "### App Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6jPjGQ0jXQk"
      },
      "source": [
        "# if RUN_TENSORBOARD_UTIL and RUN_MAIN_SIREN_APP:\n",
        "# %reload_ext tensorboard"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6fVV61Gjb6e"
      },
      "source": [
        "# if RUN_TENSORBOARD_UTIL:\n",
        "# %tensorboard --logdir {LOG_DIR}"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5hsLQERsGo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1748fcd7-1ff9-4d96-a147-d3653c840f62"
      },
      "source": [
        "if RUN_MAIN_SIREN_APP and PRUNE_MODEL_AGP:\n",
        "    !python siren_main_app.py \\\n",
        "        --logging_root {LOGGING_ROOT} \\\n",
        "        --experiment_name {EXPERIMENT_NAME} \\\n",
        "        --sidelength {SIDELENGHT} \\\n",
        "        --num_epochs 475000 \\\n",
        "        --lr 0.0001 \\\n",
        "        --n_hf {N_HF} \\\n",
        "        --n_hl {N_HL} \\\n",
        "        --lambda_L_1 0 \\\n",
        "        --lambda_L_2 0 \\\n",
        "        --epochs_til_ckpt 850 \\\n",
        "        --num-best-scores 3 \\\n",
        "        --compress {PRUNING_SCHEDULER_FILE} \\\n",
        "        --seed 0 \\\n",
        "        --cuda \\\n",
        "        --train \\\n",
        "        --evaluate \\\n",
        "        --verbose 0 \\\n",
        "        --resume-from {STATE_DICT_MODEL_FILE} \\\n",
        "        --target_sparsity 40.0 \\\n",
        "        --toll_sparsity 2.0 \\\n",
        "        --patience_sparsity 1000 \\\n",
        "        --trail_epochs 1000 \\\n",
        "        --mid_target_sparsities 5 10 20 25 30 35 40\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not find the logger configuration file (/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/logging.conf) - using default logger configuration\n",
            "Log file for this run: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/___2020.12.15-093035.log\n",
            "Random seed: 0\n",
            "\n",
            "--------------------------------------------------------\n",
            "Logging to TensorBoard - remember to execute the server:\n",
            "> tensorboard --logdir='./logs'\n",
            "\n",
            "=> created a SirenCompressingModel model with the cameramen dataset\n",
            "=> loading checkpoint /content/_mid_ckpt_epoch_299999.pth.tar\n",
            "=> Checkpoint contents:\n",
            "+----------------------+-------------+-----------------------+\n",
            "| Key                  | Type        | Value                 |\n",
            "|----------------------+-------------+-----------------------|\n",
            "| arch                 | str         | SirenCompressingModel |\n",
            "| compression_sched    | dict        |                       |\n",
            "| dataset              | str         | cameramen             |\n",
            "| epoch                | int         | 299999                |\n",
            "| extras               | dict        |                       |\n",
            "| is_parallel          | bool        | True                  |\n",
            "| optimizer_state_dict | dict        |                       |\n",
            "| optimizer_type       | type        | Adam                  |\n",
            "| state_dict           | OrderedDict |                       |\n",
            "+----------------------+-------------+-----------------------+\n",
            "\n",
            "=> Checkpoint['extras'] contents:\n",
            "+--------------------+---------+------------------+\n",
            "| Key                | Type    |            Value |\n",
            "|--------------------+---------+------------------|\n",
            "| best_epoch         | int     | 296800           |\n",
            "| best_mse           | float   |      3.07749e-05 |\n",
            "| best_psnr_score    | float64 |     51.1405      |\n",
            "| best_ssim_score    | float64 |      0.996148    |\n",
            "| current_mse        | float   |      4.85854e-05 |\n",
            "| current_psnr_score | float64 |      0.995518    |\n",
            "+--------------------+---------+------------------+\n",
            "\n",
            "Loaded compression schedule from checkpoint (epoch 299999)\n",
            "Optimizer of type <class 'torch.optim.adam.Adam'> was loaded from checkpoint\n",
            "Optimizer Args: {'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False}\n",
            "=> loaded checkpoint '/content/_mid_ckpt_epoch_299999.pth.tar' (epoch 299999)\n",
            "Reading compression schedule from: /content/siren64_5.schedule_agp.yaml\n",
            "Dataset sizes:\n",
            "\ttraining=1\n",
            "\tvalidation=1\n",
            "\ttest=1\n",
            "\n",
            "\n",
            "--- train (epoch=300050)-----------\n",
            "Training epoch: 1 samples (1 per mini-batch)\n",
            "Epoch: [300050][    1/    1]    Overall Loss 0.000062    Objective Loss 0.000062    LR 0.000100    Time 0.009207    \n",
            "--- dump pruning data (epoch=300050) ---------\n",
            "Data saved to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/data.json\n",
            "{\"module.net.1.linear.weight\": {\"epoch\": 300024, \"param_name\": \"module.net.1.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 4.98046875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.2.linear.weight\": {\"epoch\": 300024, \"param_name\": \"module.net.2.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 4.98046875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.3.linear.weight\": {\"epoch\": 300024, \"param_name\": \"module.net.3.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 4.98046875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.4.linear.weight\": {\"epoch\": 300024, \"param_name\": \"module.net.4.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 4.98046875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.5.linear.weight\": {\"epoch\": 300024, \"param_name\": \"module.net.5.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 4.98046875, \"satisfyed\": 0, \"toll\": 2.0}}\n",
            "\n",
            "Parameters:\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "|    | Name                       | Shape    |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
            "|----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
            "|  0 | module.net.0.linear.weight | (64, 2)  |           128 |            128 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.26310 | -0.02620 |    0.22456 |\n",
            "|  1 | module.net.1.linear.weight | (64, 64) |          4096 |           3892 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    4.98047 | 0.00796 |  0.00005 |    0.00651 |\n",
            "|  2 | module.net.2.linear.weight | (64, 64) |          4096 |           3892 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    4.98047 | 0.00834 |  0.00012 |    0.00690 |\n",
            "|  3 | module.net.3.linear.weight | (64, 64) |          4096 |           3892 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    4.98047 | 0.00893 |  0.00011 |    0.00733 |\n",
            "|  4 | module.net.4.linear.weight | (64, 64) |          4096 |           3892 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    4.98047 | 0.00906 | -0.00001 |    0.00739 |\n",
            "|  5 | module.net.5.linear.weight | (64, 64) |          4096 |           3892 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    4.98047 | 0.01006 |  0.00018 |    0.00808 |\n",
            "|  6 | module.net.6.weight        | (1, 64)  |            64 |             64 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.02901 | -0.00085 |    0.02817 |\n",
            "|  7 | Total sparsity:            | -        |         20672 |          19652 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    4.93421 | 0.00000 |  0.00000 |    0.00000 |\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "Total sparsity: 4.93\n",
            "\n",
            "--- validate (epoch=300050)-----------\n",
            "1 samples (1 per mini-batch)\n",
            "Epoch: [300050][    1/    1]    Loss 0.000058    \n",
            "==> MSE: 0.0000585   PSNR: 48.3531116   SSIM: 0.9943260\n",
            "\n",
            "==> Best [MSE: 0.0000376   PSNR: 50.2751405   SSIM: 0.9959557   Sparsity:0.00   NNZ-Params: 20672 on epoch: 300004]\n",
            "==> Best [MSE: 0.0000377   PSNR: 50.2597548   SSIM: 0.9959668   Sparsity:0.00   NNZ-Params: 20672 on epoch: 300005]\n",
            "==> Best [MSE: 0.0000398   PSNR: 50.0199175   SSIM: 0.9959084   Sparsity:0.00   NNZ-Params: 20672 on epoch: 300006]\n",
            "Saving checkpoint to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/_checkpoint.pth.tar\n",
            "--- dump pruning data (epoch=300225) (pruning_rate=5.001934984520129)---------\n",
            "Data saved to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/data_prune_rate_5.001934984520129_details.json\n",
            "{\"module.net.1.linear.weight\": {\"epoch\": 300124, \"param_name\": \"module.net.1.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.0048828125, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.2.linear.weight\": {\"epoch\": 300224, \"param_name\": \"module.net.2.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.029296875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.3.linear.weight\": {\"epoch\": 300224, \"param_name\": \"module.net.3.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.029296875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.4.linear.weight\": {\"epoch\": 300224, \"param_name\": \"module.net.4.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.078125, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.5.linear.weight\": {\"epoch\": 300224, \"param_name\": \"module.net.5.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.1025390625, \"satisfyed\": 0, \"toll\": 2.0}}\n",
            "\n",
            "\n",
            "--- train (epoch=300900)-----------\n",
            "Training epoch: 1 samples (1 per mini-batch)\n",
            "Epoch: [300900][    1/    1]    Overall Loss 0.000111    Objective Loss 0.000111    LR 0.000100    Time 0.009023    \n",
            "--- dump pruning data (epoch=300900) ---------\n",
            "Data saved to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/data.json\n",
            "{\"module.net.1.linear.weight\": {\"epoch\": 300724, \"param_name\": \"module.net.1.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.0537109375, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.2.linear.weight\": {\"epoch\": 300824, \"param_name\": \"module.net.2.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.126953125, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.3.linear.weight\": {\"epoch\": 300824, \"param_name\": \"module.net.3.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.126953125, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.4.linear.weight\": {\"epoch\": 300824, \"param_name\": \"module.net.4.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.322265625, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.5.linear.weight\": {\"epoch\": 300824, \"param_name\": \"module.net.5.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.46875, \"satisfyed\": 0, \"toll\": 2.0}}\n",
            "\n",
            "Parameters:\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "|    | Name                       | Shape    |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
            "|----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
            "|  0 | module.net.0.linear.weight | (64, 2)  |           128 |            128 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.26310 | -0.02619 |    0.22455 |\n",
            "|  1 | module.net.1.linear.weight | (64, 64) |          4096 |           3889 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.05371 | 0.00796 |  0.00005 |    0.00651 |\n",
            "|  2 | module.net.2.linear.weight | (64, 64) |          4096 |           3886 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.12695 | 0.00835 |  0.00012 |    0.00690 |\n",
            "|  3 | module.net.3.linear.weight | (64, 64) |          4096 |           3886 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.12695 | 0.00895 |  0.00011 |    0.00734 |\n",
            "|  4 | module.net.4.linear.weight | (64, 64) |          4096 |           3878 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.32227 | 0.00908 | -0.00001 |    0.00740 |\n",
            "|  5 | module.net.5.linear.weight | (64, 64) |          4096 |           3872 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.46875 | 0.01009 |  0.00018 |    0.00810 |\n",
            "|  6 | module.net.6.weight        | (1, 64)  |            64 |             64 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.02920 | -0.00087 |    0.02837 |\n",
            "|  7 | Total sparsity:            | -        |         20672 |          19603 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.17125 | 0.00000 |  0.00000 |    0.00000 |\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "Total sparsity: 5.17\n",
            "\n",
            "--- validate (epoch=300900)-----------\n",
            "1 samples (1 per mini-batch)\n",
            "Epoch: [300900][    1/    1]    Loss 0.000104    \n",
            "==> MSE: 0.0001038   PSNR: 45.8579838   SSIM: 0.9941939\n",
            "\n",
            "==> Best [MSE: 0.0000332   PSNR: 50.8095200   SSIM: 0.9958636   Sparsity:5.00   NNZ-Params: 19638 on epoch: 300318]\n",
            "==> Best [MSE: 0.0000332   PSNR: 50.8094808   SSIM: 0.9958631   Sparsity:5.00   NNZ-Params: 19638 on epoch: 300317]\n",
            "==> Best [MSE: 0.0000332   PSNR: 50.8091311   SSIM: 0.9958636   Sparsity:5.00   NNZ-Params: 19638 on epoch: 300319]\n",
            "Saving checkpoint to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "--- train (epoch=301750)-----------\n",
            "Training epoch: 1 samples (1 per mini-batch)\n",
            "Epoch: [301750][    1/    1]    Overall Loss 0.000045    Objective Loss 0.000045    LR 0.000100    Time 0.010120    \n",
            "--- dump pruning data (epoch=301750) ---------\n",
            "Data saved to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/data.json\n",
            "{\"module.net.1.linear.weight\": {\"epoch\": 301524, \"param_name\": \"module.net.1.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.126953125, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.2.linear.weight\": {\"epoch\": 301724, \"param_name\": \"module.net.2.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.2734375, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.3.linear.weight\": {\"epoch\": 301724, \"param_name\": \"module.net.3.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.2734375, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.4.linear.weight\": {\"epoch\": 301724, \"param_name\": \"module.net.4.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.712890625, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.5.linear.weight\": {\"epoch\": 301724, \"param_name\": \"module.net.5.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 6.005859375, \"satisfyed\": 0, \"toll\": 2.0}}\n",
            "\n",
            "Parameters:\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "|    | Name                       | Shape    |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
            "|----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
            "|  0 | module.net.0.linear.weight | (64, 2)  |           128 |            128 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.26310 | -0.02618 |    0.22456 |\n",
            "|  1 | module.net.1.linear.weight | (64, 64) |          4096 |           3886 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.12695 | 0.00796 |  0.00005 |    0.00650 |\n",
            "|  2 | module.net.2.linear.weight | (64, 64) |          4096 |           3880 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.27344 | 0.00835 |  0.00012 |    0.00690 |\n",
            "|  3 | module.net.3.linear.weight | (64, 64) |          4096 |           3880 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.27344 | 0.00895 |  0.00011 |    0.00733 |\n",
            "|  4 | module.net.4.linear.weight | (64, 64) |          4096 |           3862 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.71289 | 0.00908 | -0.00001 |    0.00739 |\n",
            "|  5 | module.net.5.linear.weight | (64, 64) |          4096 |           3850 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    6.00586 | 0.01009 |  0.00017 |    0.00810 |\n",
            "|  6 | module.net.6.weight        | (1, 64)  |            64 |             64 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.02924 | -0.00088 |    0.02840 |\n",
            "|  7 | Total sparsity:            | -        |         20672 |          19550 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.42763 | 0.00000 |  0.00000 |    0.00000 |\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "Total sparsity: 5.43\n",
            "\n",
            "--- validate (epoch=301750)-----------\n",
            "1 samples (1 per mini-batch)\n",
            "Epoch: [301750][    1/    1]    Loss 0.000046    \n",
            "==> MSE: 0.0000462   PSNR: 49.3762718   SSIM: 0.9955791\n",
            "\n",
            "==> Best [MSE: 0.0000329   PSNR: 50.8454020   SSIM: 0.9959188   Sparsity:5.34   NNZ-Params: 19568 on epoch: 301494]\n",
            "==> Best [MSE: 0.0000329   PSNR: 50.8439275   SSIM: 0.9959187   Sparsity:5.34   NNZ-Params: 19568 on epoch: 301495]\n",
            "==> Best [MSE: 0.0000330   PSNR: 50.8408215   SSIM: 0.9959169   Sparsity:5.34   NNZ-Params: 19568 on epoch: 301493]\n",
            "Saving checkpoint to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/_checkpoint.pth.tar\n",
            "\n",
            "\n",
            "--- train (epoch=302600)-----------\n",
            "Training epoch: 1 samples (1 per mini-batch)\n",
            "Epoch: [302600][    1/    1]    Overall Loss 0.000051    Objective Loss 0.000051    LR 0.000100    Time 0.008914    \n",
            "--- dump pruning data (epoch=302600) ---------\n",
            "Data saved to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/data.json\n",
            "{\"module.net.1.linear.weight\": {\"epoch\": 302424, \"param_name\": \"module.net.1.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.2001953125, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.2.linear.weight\": {\"epoch\": 302524, \"param_name\": \"module.net.2.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.419921875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.3.linear.weight\": {\"epoch\": 302524, \"param_name\": \"module.net.3.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 5.419921875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.4.linear.weight\": {\"epoch\": 302524, \"param_name\": \"module.net.4.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 6.0546875, \"satisfyed\": 0, \"toll\": 2.0}, \"module.net.5.linear.weight\": {\"epoch\": 302524, \"param_name\": \"module.net.5.linear.weight\", \"pruner\": \"AutomatedGradualPruner\", \"Fine (%)\": 6.4697265625, \"satisfyed\": 0, \"toll\": 2.0}}\n",
            "\n",
            "Parameters:\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "|    | Name                       | Shape    |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
            "|----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
            "|  0 | module.net.0.linear.weight | (64, 2)  |           128 |            128 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.26311 | -0.02617 |    0.22456 |\n",
            "|  1 | module.net.1.linear.weight | (64, 64) |          4096 |           3883 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.20020 | 0.00796 |  0.00005 |    0.00650 |\n",
            "|  2 | module.net.2.linear.weight | (64, 64) |          4096 |           3874 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.41992 | 0.00835 |  0.00012 |    0.00690 |\n",
            "|  3 | module.net.3.linear.weight | (64, 64) |          4096 |           3874 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.41992 | 0.00895 |  0.00011 |    0.00733 |\n",
            "|  4 | module.net.4.linear.weight | (64, 64) |          4096 |           3848 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    6.05469 | 0.00908 | -0.00001 |    0.00739 |\n",
            "|  5 | module.net.5.linear.weight | (64, 64) |          4096 |           3831 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    6.46973 | 0.01009 |  0.00017 |    0.00810 |\n",
            "|  6 | module.net.6.weight        | (1, 64)  |            64 |             64 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    0.00000 | 0.02926 | -0.00087 |    0.02842 |\n",
            "|  7 | Total sparsity:            | -        |         20672 |          19502 |    0.00000 |    0.00000 |        0 |  0.00000 |        0 |    5.65983 | 0.00000 |  0.00000 |    0.00000 |\n",
            "+----+----------------------------+----------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
            "Total sparsity: 5.66\n",
            "\n",
            "--- validate (epoch=302600)-----------\n",
            "1 samples (1 per mini-batch)\n",
            "Epoch: [302600][    1/    1]    Loss 0.000052    \n",
            "==> MSE: 0.0000518   PSNR: 48.8794770   SSIM: 0.9954107\n",
            "\n",
            "==> Best [MSE: 0.0000328   PSNR: 50.8607755   SSIM: 0.9959244   Sparsity:5.49   NNZ-Params: 19537 on epoch: 302023]\n",
            "==> Best [MSE: 0.0000328   PSNR: 50.8599626   SSIM: 0.9959258   Sparsity:5.57   NNZ-Params: 19520 on epoch: 302322]\n",
            "==> Best [MSE: 0.0000328   PSNR: 50.8589797   SSIM: 0.9959226   Sparsity:5.49   NNZ-Params: 19537 on epoch: 302017]\n",
            "Saving checkpoint to: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/agp_pruning/___2020.12.15-093035/_checkpoint.pth.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BWb3M1eXm3m"
      },
      "source": [
        "if RUN_MAIN_SIREN_APP and SENSITIVITY_PRUNING:\n",
        "    # {NUM_EPOCHS} \\\n",
        "    !python siren_main_app.py \\\n",
        "            --logging_root {LOGGING_ROOT} \\\n",
        "            --experiment_name {EXPERIMENT_NAME} \\\n",
        "            --sidelength {SIDELENGHT} \\\n",
        "            --num_epochs 450000 \\\n",
        "            --lr 0.001 \\\n",
        "            --n_hf {N_HF} \\\n",
        "            --n_hl {N_HL} \\\n",
        "            --lambda_L_1 0 \\\n",
        "            --lambda_L_2 0 \\\n",
        "            --epochs_til_ckpt 950 \\\n",
        "            --num-best-scores 5 \\\n",
        "            --compress {PRUNING_SCHEDULER_FILE} \\\n",
        "            --seed 0 \\\n",
        "            --cuda \\\n",
        "            --train \\\n",
        "            --evaluate \\\n",
        "            --verbose 0 \\\n",
        "            --resume-from {STATE_DICT_MODEL_FILE}\n",
        "    # --reset-optimizer \\\n",
        "    # --exp-load-weights-from\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz6Cly6riIff"
      },
      "source": [
        "if RUN_MAIN_SIREN_APP and LEVEL_PRUNING:\n",
        "    !python siren_main_app.py \\\n",
        "        --logging_root {LOGGING_ROOT} \\\n",
        "        --experiment_name {EXPERIMENT_NAME} \\\n",
        "        --sidelength {SIDELENGHT} \\\n",
        "        --num_epochs 434999 \\\n",
        "        --lr 0.0001 \\\n",
        "        --n_hf {N_HF} \\\n",
        "        --n_hl {N_HL} \\\n",
        "        --lambda_L_1 0 \\\n",
        "        --lambda_L_2 0 \\\n",
        "        --epochs_til_ckpt 200 \\\n",
        "        --num-best-scores 5 \\\n",
        "        --compress {PRUNING_SCHEDULER_FILE} \\\n",
        "        --seed 0 \\\n",
        "        --cuda \\\n",
        "        --train \\\n",
        "        --evaluate \\\n",
        "        --verbose 0 \\\n",
        "        --resume-from {STATE_DICT_MODEL_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNa7CbgwsZhE"
      },
      "source": [
        "if RUN_MAIN_SIREN_APP and PLAIN_TRAINING:\n",
        "    !python siren_main_app.py \\\n",
        "            --logging_root {LOGGING_ROOT} \\\n",
        "            --experiment_name 'train' \\\n",
        "            --sidelength {SIDELENGHT} \\\n",
        "            --num_epochs {NUM_EPOCHS} \\\n",
        "            --lr 0.001 \\\n",
        "            --n_hf {N_HF} \\\n",
        "            --n_hl {N_HL} \\\n",
        "            --lambda_L_1 0 \\\n",
        "            --lambda_L_2 0 \\\n",
        "            --epochs_til_ckpt 500 \\\n",
        "            --num-best-scores 5 \\\n",
        "            --seed 0 \\\n",
        "            --cuda \\\n",
        "            --train \\\n",
        "            --evaluate \\\n",
        "            --verbose 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g6yHBYY2GHD"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhz8udmw1Z-6"
      },
      "source": [
        "if EVAL_MODEL:\n",
        "    !python siren_main_app.py \\\n",
        "            --logging_root {LOGGING_ROOT_EVAL} \\\n",
        "            --experiment_name 'train' \\\n",
        "            --sidelength {SIDELENGHT} \\\n",
        "            --n_hf {N_HF} \\\n",
        "            --n_hl {N_HL} \\\n",
        "            --seed 0 \\\n",
        "            --cuda \\\n",
        "            --evaluate \\\n",
        "            --verbose 0 \\\n",
        "            --exp-load-weights-from {STATE_DICT_MODEL_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5qJLBJUhjhL"
      },
      "source": [
        "Could not find the logger configuration file (/content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/eval-res/logging.conf) - using default logger configuration\n",
        "Log file for this run: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/eval-res/___2020.12.05-104940/___2020.12.05-104940.log\n",
        "Random seed: 0\n",
        "\n",
        "--------------------------------------------------------\n",
        "Logging to TensorBoard - remember to execute the server:\n",
        "> tensorboard --logdir='./logs'\n",
        "\n",
        "=> created a SirenCompressingModel model with the cameramen dataset\n",
        "=> loading checkpoint /content/_mid_ckpt_epoch_299999.pth.tar\n",
        "=> Checkpoint contents:\n",
        "+----------------------+-------------+-----------------------+\n",
        "| Key                  | Type        | Value                 |\n",
        "|----------------------+-------------+-----------------------|\n",
        "| arch                 | str         | SirenCompressingModel |\n",
        "| compression_sched    | dict        |                       |\n",
        "| dataset              | str         | cameramen             |\n",
        "| epoch                | int         | 299999                |\n",
        "| extras               | dict        |                       |\n",
        "| is_parallel          | bool        | True                  |\n",
        "| optimizer_state_dict | dict        |                       |\n",
        "| optimizer_type       | type        | Adam                  |\n",
        "| state_dict           | OrderedDict |                       |\n",
        "+----------------------+-------------+-----------------------+\n",
        "\n",
        "=> Checkpoint['extras'] contents:\n",
        "+--------------------+---------+------------------+\n",
        "| Key                | Type    |            Value |\n",
        "|--------------------+---------+------------------|\n",
        "| best_epoch         | int     | 296800           |\n",
        "| best_mse           | float   |      3.07749e-05 |\n",
        "| best_psnr_score    | float64 |     51.1405      |\n",
        "| best_ssim_score    | float64 |      0.996148    |\n",
        "| current_mse        | float   |      4.85854e-05 |\n",
        "| current_psnr_score | float64 |      0.995518    |\n",
        "+--------------------+---------+------------------+\n",
        "\n",
        "Loaded compression schedule from checkpoint (epoch 299999)\n",
        "=> loaded 'state_dict' from checkpoint '/content/_mid_ckpt_epoch_299999.pth.tar'\n",
        "Dataset sizes:\n",
        "\ttest=1\n",
        "--- test ---------------------\n",
        "==> Loss: 0.0000486   PSNR: 49.1567465   SSIM: 0.9955182\n",
        "\n",
        "\n",
        "Log file for this run: /content/drive/MyDrive/Siren-Deep-Learning-Analyses/results/cameramen/eval-res/___2020.12.05-104940/___2020.12.05-104940.log\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amu7gUOuvOi5"
      },
      "source": [
        "if EVAL_MODEL:\n",
        "    !python siren_main_app.py \\\n",
        "            --logging_root {LOGGING_ROOT_EVAL} \\\n",
        "            --experiment_name 'train' \\\n",
        "            --sidelength {SIDELENGHT} \\\n",
        "            --n_hf {N_HF} \\\n",
        "            --n_hl {N_HL} \\\n",
        "            --seed 0 \\\n",
        "            --cuda \\\n",
        "            --summary 'sparsity' \\\n",
        "            --compress {PRUNING_SCHEDULER_FILE} \\\n",
        "            --verbose 0 \\\n",
        "            --exp-load-weights-from {STATE_DICT_MODEL_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2xTMIGfvCEL"
      },
      "source": [
        "if EVAL_MODEL and LEVEL_PRUNING:\n",
        "    !python siren_main_app.py \\\n",
        "            --logging_root {LOGGING_ROOT_EVAL} \\\n",
        "            --experiment_name 'train' \\\n",
        "            --sidelength {SIDELENGHT} \\\n",
        "            --n_hf {N_HF} \\\n",
        "            --n_hl {N_HL} \\\n",
        "            --seed 0 \\\n",
        "            --cuda \\\n",
        "            --evaluate \\\n",
        "            --compress {PRUNING_SCHEDULER_FILE} \\\n",
        "            --verbose 0 \\\n",
        "            --exp-load-weights-from {STATE_DICT_MODEL_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}