



\begin{frame}
\frametitle{Selected Compression Techniques}
The Compression Techniques we decided to adopt and investigate among the wide varieaty of possible choices are the two following:
\begin{itemize}
\item \textbf{\textit{Automated Gradual Pruning}} by \textit{Michael Zhu et al., 2017} - an instance of a possible pruning like compressing method:
\begin{itemize}
\item Model pruning is the art of discarding the weights that \textbf{do not improve a model's performance}, in other words \textbf{non-significant or non-salient parameters};
\item Careful pruning enables us to compress and deploy our \textbf{state-of-the-art neural networks} onto \textbf{mobile phones and other resource-constrained devices}.
\end{itemize}
\item \textbf{\textit{Linear Range Quantization}} by \textit{ Benoit et al., 2018} - an instance of a possible quantizing aware training method;
\end{itemize}

\end{frame}
