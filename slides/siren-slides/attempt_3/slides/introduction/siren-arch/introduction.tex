
\begin{frame}
    \frametitle{Siren Deep Neural Network Architectures}
        % \centering \Huge
        \begin{center}
            {\fontsize{40}{50}\selectfont \emph{Siren DNNs}}
        \end{center}
        \begin{equation*}
            F(x, \Phi, \nabla_{x}\Phi, \nabla_{x}^{2}\Phi, \dots) = 0, \Phi:x\rightarrow\Phi(x)
        \end{equation*}
        \begin{center}
            \emph{Short Presentation of Siren Architecture}
        \end{center}
    \end{frame}


\begin{frame}
    \frametitle{Siren Deep Neural Network Architectures (2)}
        Main characteristics of Siren based Deep Models employed for as major purpose of implicitly representing input processed image:
        \begin{itemize}
        \item It belongs to \textbf{MLP family} of Deep Learning Networks, this means that It resembles a Fully Connected Architecture;
        \item It employes as non-linear activation function a \textbf{trigonometric sine function}.
        \item It is feeded by means of a set of \textbf{input coordinates} throught which \textbf{output pixel value}, in other words pixel magnitude, in a given scale and so range of values is predicted;
        \item It does not employes a well-known and widespread weigths initialization technique as \textbf{\emph{Xavier Initialization}} but instead decided to adopt a \textbf{\emph{Custom Uniform Initialization}}, as described within the same Siren paper.
        \end{itemize}
    \end{frame}
